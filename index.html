
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Amber Srivastava</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Amber Srivastava</div>
<div class="menu-item"><a href="index.html" class="current">home</a></div>
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
</td>
<td id="layout-content">
  
  <div id="toptitle">
<h1>Amber Srivastava<br /></h1>
</div>
  
<table class="imgtable"><tr><td>
<img src="Figs/AmberSrivastava.jpeg" alt="Amber Srivastava" width="173px" height="180px" />&nbsp;</td>

<td align="left"> Postdoctoral Researcher <br />
<a href="https://ee.ethz.ch">Department of Information Technology and Electrical Engineering</a> <br />
<a href="https://control.ee.ethz.ch">Automatic Control Laboratory</a> <br />
<a href="https://ethz.ch/en.html">ETH Z&uuml;rich</a> </p>


<p>  <a href="mailto:asrivastava@control.ee.ethz.ch">asrivastava@control.ee.ethz.ch</a><br />
ETL I 13 <br/>
Physikstrasse 3 <br/>
8092 Z&uuml;rich, Switzerland <br/></p>


</td></tr></table>
<h2>About Me</h2>
<p>I am a postdoctoral researcher supervised by <a href="http://people.ee.ethz.ch/~rsmith/">Dr. Roy S. Smith </a> in the Automatic Control Laboratory at the Swiss Federal Institute of Technology (ETH, Z&uuml;rich) in Switzerland. Here, I am working on the topics of system identification, predictive and data-driven control of large scale systems. Prior to this, I was at the University of Illinois Urbana Champaign 2015-2018 where I completed my PhD under the supervision of <a href="http://salapaka.web.engr.illinois.edu">Dr. Srinivasa M. Salapaka </a>. My thesis deals with sequential decision making problems; particularly, where the underlying system parameters need to be simultaneously optimised along with the decision policy. We refer to them as parameterised sequential decision making problems, or para-SDM, and develop build-up on tools from statistical physics, control theory, learning and optimization to address them. These problems are ubiquitous; for instance, the job-shop scheduling, industrial process optimization, network design, clustering and classification are para-SDM problems.

Currently my research is in the following topics </p>
<ul>
<li><p> Learning, Identification, and control of large scale networks </p>
</li>
<li><p> Cyber-physical Manufacturing systems - Industry 4.0</p>
</li>
<li><p> Data-driven Framework for Combinatorial Optimization Problems</p>
</li>
</ul>

I received a Masters in Mathematics from UIUC in 2020, and completed my Bachelors in Technology from Indian Institute of Technology Kanpur in 2014. For a brief period between 2014 and 2015, I was a Project Engineer withITC Ltd (FMCG in India). 



<h2>News</h2>
<ul>
	<li><p><b>03/2022:</b> Our paper "On the choice of Number of Superstates in the Aggregation of Markov Chains" has been accepted for publication in <a href="https://doi.org/10.1016/j.patrec.2022.05.019">Pattern Recognition Letters</a>. This paper proposes a notion of <b>Marginal Return</b> to compare different aggregated models of a Markov chain, and appropriately identify the best representative model.</p>
  </li>



<!  <li><p><b>03/2022:</b> Our paper "Connectivity of the Feasible and Sublevel Sets of Dynamic Output Feedback Control with Robustness Constraints" has been posted <a href="https://arxiv.org/pdf/2203.11177.pdf">on arxiv</a>. This paper brings new insights for understanding policy optimization in the output feedback setting. </p>
  </li> 
  
  <li><p><b>01/2022:</b> Our paper "Revisiting PGD Attacks for Stability Analysis of Large-Scale Nonlinear Systems and Perception-Based Control" has been posted <a href="https://arxiv.org/pdf/2201.00801.pdf">on arxiv</a>. This paper tailors PGD attacks from the adversarial learning literature as scalable analysis tools for approximating the region of attraction (ROA) of nonlinear control systems with large-scale neural network policies and/or high-dimensional image observations.</p>
  </li>
  
    <li><p><b>11/2021:</b> Our paper "Model-Free μ Synthesis via Adversarial Reinforcement Learning" has been posted <a href="https://arxiv.org/pdf/2111.15537.pdf">on arxiv</a>. This paper builds a connection between adversarial reinforcement learning and the famous DK iteration algorithm from robust control.</p>
   <p><b>Update:</b> The above paper has been accepted to American Control Conference (ACC) 2022.</p>
  </li>
  
   <li><p><b>09/2021:</b> Our paper "Derivative-Free Policy Optimization for Linear Risk-Sensitive and Robust Control Design: Implicit Regularization and Sample Complexity" has been accepted to <a href="https://papers.nips.cc/paper/2021/hash/1714726c817af50457d810aae9d27a2e-Abstract.html">NeurIPS 2021</a>. </p>
  </li>
  
   <li><p><b>03/2021:</b> Delighted to receive the <a href="https://www.amazon.science/research-awards/program-updates/2020-amazon-research-awards-recipients-announced">2020 Amazon Research Award</a>. Big thanks to Amazon!</p>
  </li>
  
   <li><p><b>02/2021:</b> Thrilled to receive the <a href="https://nsf.gov/awardsearch/showAward?AWD_ID=2048168&HistoricalAwards=false">NSF CAREER award</a> on "Interplay between Control Theory and Machine Learning." Big thanks to NSF!</p>
  </li>
  
   <li><p><b>09/2020:</b> Our paper "On the Stability and Convergence of Robust Adversarial Reinforcement Learning: A Case Study on Linear Quadratic Systems" has been accepted to <a href="https://proceedings.neurips.cc/paper/2020/hash/fb2e203234df6dee15934e448ee88971-Abstract.html">NeurIPS 2020</a>. </p>
  </li>
  
     <li><p><b>03/2020:</b> Our paper "Analysis of Biased Stochastic Gradient Descent Using Sequential Semidefinite Programs" has been accepted to <a href="https://link.springer.com/article/10.1007%2Fs10107-020-01486-1">Mathematical Programming</a>. A full-text view-only version of the final paper can be found <a href="https://rdcu.be/b3b59">here</a>. </p>
  </li>
  
   <li><p><b>10/2019:</b> Our paper "Policy Optimization for H2 Linear Control with H-infinity Robustness Guarantee: Implicit Regularization and Global Convergence" has been posted <a href="https://arxiv.org/pdf/1910.09496.pdf">on arxiv</a>. This paper studies the implicit regularization mechanism in policy-based reinforcement learning for robust control design.</p>
  <p><b>Update I:</b> A conference version of the above paper has been accepted to <a href="https://sites.google.com/berkeley.edu/l4dc/home">L4DC 2020</a>. (one of 14/131 papers selected for oral presentation)</p>
    <p><b>Update II:</b> The journal version of the above paper has been accepted to SIAM Journal on Control and Optimization (SICON).</p>
  </li>
  
  <li><p><b>06/2019:</b> Our paper "Characterizing the Exact Behaviors of Temporal Difference Learning Algorithms Using Markov Jump Linear System Theory" has been posted <a href="https://arxiv.org/pdf/1906.06781.pdf">on arxiv</a>. This is my first paper on analyzing reinforcement learning algorithms using control theory!</p>
<p><b>Update:</b> The above paper has been accepted to <a href="https://nips.cc/Conferences/2019/Schedule?showEvent=13909">NeurIPS 2019</a>. The arxiv version of the paper has been revised.</p>
  </li>
  
<li><p><b>08/2018:</b> I started as an Assistant Professor in the Electrical and Computer Engineering Department at the University of Illinois at Urbana-Champaign.</p>
</li>>
</ul>



</td>
</tr>
</table>
</body>
</html>
